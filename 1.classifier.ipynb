{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Types of ML Classification Algorithms:</h2>\n",
    "\n",
    "Classification Algorithms can be further divided into the Mainly two category:\n",
    "\n",
    "<h3>Linear Models</h3>\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Support Vector Machines\n",
    "\n",
    "<h3>Non-linear Models</h3>\n",
    "\n",
    "1. K-Nearest Neighbours\n",
    "2. Kernel SVM\n",
    "3. Naïve Bayes\n",
    "4. Decision Tree Classification\n",
    "5. Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/snehvora/Desktop/Machine Learning/diabetes.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BY USING LINEAR REGRESSION PROVIDED IN SKLEARN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "classifier= LogisticRegression(random_state=0)  \n",
    "classifier.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[180,  19],\n",
       "       [ 49,  60]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test,y_pred)  \n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING PYTORCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd279045510>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TensorDataset(x_train,y_train)\n",
    "data_loader = DataLoader(data,batch_size=100)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Log Loss or Cross-Entropy Loss:</h2>\n",
    "\n",
    "Loss = -(ylog(p)+(1-y)log(1-p))  \n",
    "\n",
    "Where y= Actual output, p= predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,in_size,hidden_size,out_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_size,hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size,out_size)\n",
    "\n",
    "    def forward(self,xb):\n",
    "        xb = xb.view(xb.size(0),-1)\n",
    "        out = self.linear1(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "model = Model(in_size=8, hidden_size=4, out_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,data_loader,model,loss_func,opt):\n",
    "    batch_size = []\n",
    "    batch_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in data_loader:\n",
    "            batch_size.append(len(xb))\n",
    "            out = model(xb.float())\n",
    "            loss = loss_func(out,yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            batch_loss.append(loss.item())\n",
    "        sum1 = 0\n",
    "        for a,b in zip(batch_loss,batch_size):\n",
    "            sum1 += a*b\n",
    "        print('Epoch :'+ str(epoch+1)+ '/' + str(epochs)+'  '+'Loss : '+ str(sum1/np.sum(batch_size)))\n",
    "        batch_size = []\n",
    "        batch_loss = []\n",
    "\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1/200  Loss : 0.6737306636312733\n",
      "Epoch :2/200  Loss : 0.6688556101011194\n",
      "Epoch :3/200  Loss : 0.664380757705025\n",
      "Epoch :4/200  Loss : 0.6601488434750101\n",
      "Epoch :5/200  Loss : 0.6560857425565305\n",
      "Epoch :6/200  Loss : 0.652168139167454\n",
      "Epoch :7/200  Loss : 0.6483415235643801\n",
      "Epoch :8/200  Loss : 0.6445772673772729\n",
      "Epoch :9/200  Loss : 0.6408765393754711\n",
      "Epoch :10/200  Loss : 0.6372332054635753\n",
      "Epoch :11/200  Loss : 0.6336146826329438\n",
      "Epoch :12/200  Loss : 0.6300057691076527\n",
      "Epoch :13/200  Loss : 0.626352336095727\n",
      "Epoch :14/200  Loss : 0.6226265793261321\n",
      "Epoch :15/200  Loss : 0.6188638495362323\n",
      "Epoch :16/200  Loss : 0.615071283734363\n",
      "Epoch :17/200  Loss : 0.6112958788871765\n",
      "Epoch :18/200  Loss : 0.607498692429584\n",
      "Epoch :19/200  Loss : 0.6036779388137485\n",
      "Epoch :20/200  Loss : 0.5998406824858292\n",
      "Epoch :21/200  Loss : 0.5959368166716202\n",
      "Epoch :22/200  Loss : 0.5920635798703069\n",
      "Epoch :23/200  Loss : 0.5882061201593151\n",
      "Epoch :24/200  Loss : 0.5843486086181973\n",
      "Epoch :25/200  Loss : 0.5804727310719697\n",
      "Epoch :26/200  Loss : 0.5766005256901616\n",
      "Epoch :27/200  Loss : 0.5727538388708363\n",
      "Epoch :28/200  Loss : 0.5689341322235439\n",
      "Epoch :29/200  Loss : 0.5651501702225726\n",
      "Epoch :30/200  Loss : 0.5614302210185839\n",
      "Epoch :31/200  Loss : 0.5577686454938806\n",
      "Epoch :32/200  Loss : 0.5541883655216383\n",
      "Epoch :33/200  Loss : 0.5506904332534127\n",
      "Epoch :34/200  Loss : 0.5472692328950634\n",
      "Epoch :35/200  Loss : 0.5439217608907948\n",
      "Epoch :36/200  Loss : 0.5406257743420808\n",
      "Epoch :37/200  Loss : 0.5374004983383677\n",
      "Epoch :38/200  Loss : 0.5342427142288374\n",
      "Epoch :39/200  Loss : 0.5311887406784556\n",
      "Epoch :40/200  Loss : 0.5282238294248995\n",
      "Epoch :41/200  Loss : 0.5253483678983606\n",
      "Epoch :42/200  Loss : 0.5225456512492636\n",
      "Epoch :43/200  Loss : 0.5198003390560979\n",
      "Epoch :44/200  Loss : 0.517132220060929\n",
      "Epoch :45/200  Loss : 0.514538577069407\n",
      "Epoch :46/200  Loss : 0.5119530688161436\n",
      "Epoch :47/200  Loss : 0.5094032754068789\n",
      "Epoch :48/200  Loss : 0.5069291462068972\n",
      "Epoch :49/200  Loss : 0.5045521738736526\n",
      "Epoch :50/200  Loss : 0.5022804944411569\n",
      "Epoch :51/200  Loss : 0.5000966281994529\n",
      "Epoch :52/200  Loss : 0.4980157121368077\n",
      "Epoch :53/200  Loss : 0.49602578645167145\n",
      "Epoch :54/200  Loss : 0.494128299796063\n",
      "Epoch :55/200  Loss : 0.492311910442684\n",
      "Epoch :56/200  Loss : 0.49053883682126587\n",
      "Epoch :57/200  Loss : 0.4888102088285529\n",
      "Epoch :58/200  Loss : 0.48713351850924286\n",
      "Epoch :59/200  Loss : 0.4855046829451685\n",
      "Epoch :60/200  Loss : 0.4839186836843905\n",
      "Epoch :61/200  Loss : 0.4823791449484618\n",
      "Epoch :62/200  Loss : 0.4808985500232033\n",
      "Epoch :63/200  Loss : 0.47947541915852093\n",
      "Epoch :64/200  Loss : 0.47808636530585913\n",
      "Epoch :65/200  Loss : 0.4767291817976081\n",
      "Epoch :66/200  Loss : 0.47539664610572485\n",
      "Epoch :67/200  Loss : 0.47411026514094806\n",
      "Epoch :68/200  Loss : 0.4728801639183708\n",
      "Epoch :69/200  Loss : 0.4717106676619986\n",
      "Epoch :70/200  Loss : 0.47061422337656433\n",
      "Epoch :71/200  Loss : 0.4695795528266741\n",
      "Epoch :72/200  Loss : 0.4685928251432336\n",
      "Epoch :73/200  Loss : 0.46767477496810583\n",
      "Epoch :74/200  Loss : 0.4668059439762779\n",
      "Epoch :75/200  Loss : 0.46598083687865216\n",
      "Epoch :76/200  Loss : 0.4651879629363184\n",
      "Epoch :77/200  Loss : 0.4644179240516994\n",
      "Epoch :78/200  Loss : 0.4636784390262935\n",
      "Epoch :79/200  Loss : 0.4629658927088198\n",
      "Epoch :80/200  Loss : 0.46227904765502265\n",
      "Epoch :81/200  Loss : 0.46161604964214825\n",
      "Epoch :82/200  Loss : 0.46097668227942096\n",
      "Epoch :83/200  Loss : 0.4603755901689115\n",
      "Epoch :84/200  Loss : 0.4597985226175059\n",
      "Epoch :85/200  Loss : 0.45924540058426233\n",
      "Epoch :86/200  Loss : 0.4587115658366162\n",
      "Epoch :87/200  Loss : 0.4581936429376188\n",
      "Epoch :88/200  Loss : 0.45769635490749194\n",
      "Epoch :89/200  Loss : 0.45721411316291144\n",
      "Epoch :90/200  Loss : 0.45674714834793756\n",
      "Epoch :91/200  Loss : 0.4562874384548353\n",
      "Epoch :92/200  Loss : 0.4558385105236717\n",
      "Epoch :93/200  Loss : 0.4554051860519078\n",
      "Epoch :94/200  Loss : 0.45498017901959625\n",
      "Epoch :95/200  Loss : 0.45455910848534625\n",
      "Epoch :96/200  Loss : 0.454147660213968\n",
      "Epoch :97/200  Loss : 0.453750289004782\n",
      "Epoch :98/200  Loss : 0.45336454329283343\n",
      "Epoch :99/200  Loss : 0.45299100616703863\n",
      "Epoch :100/200  Loss : 0.45263445118199225\n",
      "Epoch :101/200  Loss : 0.45229068398475647\n",
      "Epoch :102/200  Loss : 0.45196191383444745\n",
      "Epoch :103/200  Loss : 0.45164658841879474\n",
      "Epoch :104/200  Loss : 0.45133605210677435\n",
      "Epoch :105/200  Loss : 0.4510375222434168\n",
      "Epoch :106/200  Loss : 0.4507514238357544\n",
      "Epoch :107/200  Loss : 0.45047663605731464\n",
      "Epoch :108/200  Loss : 0.45021549644677533\n",
      "Epoch :109/200  Loss : 0.4499601682891016\n",
      "Epoch :110/200  Loss : 0.4497194380863853\n",
      "Epoch :111/200  Loss : 0.4494848264300305\n",
      "Epoch :112/200  Loss : 0.4492573388244795\n",
      "Epoch :113/200  Loss : 0.44903717999872955\n",
      "Epoch :114/200  Loss : 0.4488168436547984\n",
      "Epoch :115/200  Loss : 0.4486051318438157\n",
      "Epoch :116/200  Loss : 0.44839647541875427\n",
      "Epoch :117/200  Loss : 0.4481918487859809\n",
      "Epoch :118/200  Loss : 0.4479954877625341\n",
      "Epoch :119/200  Loss : 0.4477951487769251\n",
      "Epoch :120/200  Loss : 0.4476042091846466\n",
      "Epoch :121/200  Loss : 0.44741212932959845\n",
      "Epoch :122/200  Loss : 0.4472204809603484\n",
      "Epoch :123/200  Loss : 0.4470296566901\n",
      "Epoch :124/200  Loss : 0.44683441260586615\n",
      "Epoch :125/200  Loss : 0.4466448711312335\n",
      "Epoch :126/200  Loss : 0.4464510653329932\n",
      "Epoch :127/200  Loss : 0.4462605377902155\n",
      "Epoch :128/200  Loss : 0.4460741242636805\n",
      "Epoch :129/200  Loss : 0.4458896569583727\n",
      "Epoch :130/200  Loss : 0.4457051676252614\n",
      "Epoch :131/200  Loss : 0.44552258952804236\n",
      "Epoch :132/200  Loss : 0.4453382854876311\n",
      "Epoch :133/200  Loss : 0.4451530212941377\n",
      "Epoch :134/200  Loss : 0.44495835122854815\n",
      "Epoch :135/200  Loss : 0.44475529893584875\n",
      "Epoch :136/200  Loss : 0.44455318735993427\n",
      "Epoch :137/200  Loss : 0.4443550122820813\n",
      "Epoch :138/200  Loss : 0.44415949349818024\n",
      "Epoch :139/200  Loss : 0.4439563945583675\n",
      "Epoch :140/200  Loss : 0.4437522538330244\n",
      "Epoch :141/200  Loss : 0.4435491380484208\n",
      "Epoch :142/200  Loss : 0.4433432467605757\n",
      "Epoch :143/200  Loss : 0.4431430995464325\n",
      "Epoch :144/200  Loss : 0.4429460401120393\n",
      "Epoch :145/200  Loss : 0.4427498488322548\n",
      "Epoch :146/200  Loss : 0.4425568373306938\n",
      "Epoch :147/200  Loss : 0.4423714396746262\n",
      "Epoch :148/200  Loss : 0.442188649073891\n",
      "Epoch :149/200  Loss : 0.442007786553839\n",
      "Epoch :150/200  Loss : 0.44182684499284497\n",
      "Epoch :151/200  Loss : 0.44164531256841577\n",
      "Epoch :152/200  Loss : 0.44147057766499725\n",
      "Epoch :153/200  Loss : 0.44129339767538983\n",
      "Epoch :154/200  Loss : 0.4411134123802185\n",
      "Epoch :155/200  Loss : 0.44093408144038654\n",
      "Epoch :156/200  Loss : 0.4407564544159433\n",
      "Epoch :157/200  Loss : 0.4405797629252724\n",
      "Epoch :158/200  Loss : 0.4404014284196107\n",
      "Epoch :159/200  Loss : 0.44022542238235474\n",
      "Epoch :160/200  Loss : 0.4400526622067327\n",
      "Epoch :161/200  Loss : 0.43987836138061853\n",
      "Epoch :162/200  Loss : 0.43970629832018976\n",
      "Epoch :163/200  Loss : 0.43953611151031824\n",
      "Epoch :164/200  Loss : 0.43936293798944226\n",
      "Epoch :165/200  Loss : 0.4391866663227911\n",
      "Epoch :166/200  Loss : 0.43899973319924396\n",
      "Epoch :167/200  Loss : 0.4388075833735259\n",
      "Epoch :168/200  Loss : 0.43861166290614917\n",
      "Epoch :169/200  Loss : 0.43841429896976636\n",
      "Epoch :170/200  Loss : 0.43821763214857684\n",
      "Epoch :171/200  Loss : 0.43802676511847455\n",
      "Epoch :172/200  Loss : 0.4378526379232821\n",
      "Epoch :173/200  Loss : 0.43768848932307697\n",
      "Epoch :174/200  Loss : 0.4375247177870377\n",
      "Epoch :175/200  Loss : 0.4373633058174797\n",
      "Epoch :176/200  Loss : 0.43720747983973957\n",
      "Epoch :177/200  Loss : 0.4370575832284015\n",
      "Epoch :178/200  Loss : 0.43690429692683014\n",
      "Epoch :179/200  Loss : 0.43675381722657575\n",
      "Epoch :180/200  Loss : 0.436604301566663\n",
      "Epoch :181/200  Loss : 0.4364545980225439\n",
      "Epoch :182/200  Loss : 0.4363003243570742\n",
      "Epoch :183/200  Loss : 0.43613739635633386\n",
      "Epoch :184/200  Loss : 0.4359705979409425\n",
      "Epoch :185/200  Loss : 0.43580359090929444\n",
      "Epoch :186/200  Loss : 0.43563485275144165\n",
      "Epoch :187/200  Loss : 0.43547232513842377\n",
      "Epoch :188/200  Loss : 0.43529877066612244\n",
      "Epoch :189/200  Loss : 0.4351276677587758\n",
      "Epoch :190/200  Loss : 0.43496191112891486\n",
      "Epoch :191/200  Loss : 0.4347849488258362\n",
      "Epoch :192/200  Loss : 0.4346036496369735\n",
      "Epoch :193/200  Loss : 0.4344219746796981\n",
      "Epoch :194/200  Loss : 0.4342421681984611\n",
      "Epoch :195/200  Loss : 0.43406450230142346\n",
      "Epoch :196/200  Loss : 0.4338912095712579\n",
      "Epoch :197/200  Loss : 0.43372747690781305\n",
      "Epoch :198/200  Loss : 0.4335680241170137\n",
      "Epoch :199/200  Loss : 0.43341538180475647\n",
      "Epoch :200/200  Loss : 0.43326857815618103\n"
     ]
    }
   ],
   "source": [
    "fit(epochs,data_loader,model,loss_func,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "y_pred = model(x_test.float())\n",
    "_,preds = torch.max(y_pred,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[171,  28],\n",
       "       [ 42,  67]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,preds)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
